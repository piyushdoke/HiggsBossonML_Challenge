{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = genfromtxt('training.csv',dtype = str, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = training_data[1:,-1]\n",
    "train_labels = (train_labels == 's').astype(np.int32)\n",
    "train_data = training_data[1:,1:31]\n",
    "train_data = train_data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.where(train_data == -999)\n",
    "new_r, new_c = np.where(train_data != -999)\n",
    "mean_list = np.mean(train_data[new_r][new_c], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64), array([], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(a)):\n",
    "    train_data[a[i]][train_data[a[i]] == -999] = mean_list[b[i]]\n",
    "x, y = np.where(train_data == -999)\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = scaler.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(.95)\n",
    "pca.fit(train_data)\n",
    "pca.n_components_\n",
    "train_data = pca.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(pca.n_components_)\n",
    "np.savetxt(\"training_data_pca.csv\", train_data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Pearson's correlation\n",
    "from scipy.stats import pearsonr\n",
    "n = len(train_data[0])\n",
    "dict1={}\n",
    "for i in range(1,n-2):\n",
    "    l= []\n",
    "    for j in range(1,n-2):\n",
    "        corr, _ = pearsonr(train_data[:,i], train_data[:,j])\n",
    "        l.append(corr)\n",
    "    dict1[training_data[0][i]]=l\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(dict1, orient='index',columns=training_data[0][1:n-2])\n",
    "\n",
    "\n",
    "#check for relations where there is 0.95 correlation\n",
    "dict2={}\n",
    "for key in dict1:\n",
    "    n = len(dict1[key])\n",
    "    for i in range(0,n):\n",
    "        if dict1[key][i]>=0.95 and key!=training_data[0][i+1]:\n",
    "            if key>training_data[0][i+1]:\n",
    "                a = training_data[0][i+1]\n",
    "                b = key\n",
    "            else:\n",
    "                a = key\n",
    "                b = training_data[0][i+1]\n",
    "            dict2[(a,b)]=dict1[key][i]\n",
    "\n",
    "for key in dict2:\n",
    "    print (key,dict2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataCsv = dataframe.to_csv(index=True)\n",
    "f = open('correlation.csv','w+')\n",
    "f.write(dataCsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of DER_mass_MC\n",
    "import random\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "\n",
    "filename='training.csv'\n",
    "data = genfromtxt(filename,dtype = float, delimiter=',');\n",
    "data1 = genfromtxt(filename,dtype = str, delimiter=',');\n",
    "Mass = data[1:,1]\n",
    "Y = data1[1:,32]\n",
    "Y = np.array(Y)\n",
    "\n",
    "Mass = np.array(Mass)\n",
    "Msignal = Mass[Y=='s'];\n",
    "Mbackground = Mass[Y=='b'];\n",
    "bins = numpy.linspace(9, 500, 50)\n",
    "pyplot.hist(Mbackground, bins, alpha=0.5, label='Background')\n",
    "pyplot.hist(Msignal, bins, alpha=0.5, label='Signal')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.xlabel('DER_mass_MMC')\n",
    "pyplot.ylabel('Number of events')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72692"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf = clf.fit(train_data[:200000], train_labels[:200000])\n",
    "clf.score(train_data[200000:],train_labels[200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanika/.local/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0992e7828b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanika/.local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanika/.local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanika/.local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanika/.local/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanika/.local/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
    "clf = clf.fit(train_data[:200000], train_labels[:200000])\n",
    "clf.score(train_data[200000:],train_labels[200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf = clf.fit(train_data[:200000], train_labels[:200000])\n",
    "clf.score(train_data[200000:],train_labels[200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(train_data[:200000], train_labels[:200000])\n",
    "clf.score(train_data[200000:],train_labels[200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(probability=True)\n",
    "clf.fit(train_data[:200000], train_labels[:200000])\n",
    "clf.score(train_data[200000:], train_labels[200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Experimenting for different Regularization parameters\n",
      "('C:', 0.001, ' Svm score for test data:', 0.7679)\n",
      "('C:', 0.01, ' Svm score for test data:', 0.81021)\n",
      "('C:', 0.1, ' Svm score for test data:', 0.82826)\n",
      "('C:', 1, ' Svm score for test data:', 0.83924)\n",
      "('C:', 10, ' Svm score for test data:', 0.85133)\n",
      "\n",
      "Experimenting for different Degrees for polynomial kernel\n",
      "('Degree ', 0, ' Svm score for test data:', 0.65666)\n",
      "('Degree ', 1, ' Svm score for test data:', 0.72278)\n",
      "('Degree ', 2, ' Svm score for test data:', 0.80722)\n",
      "('Degree ', 3, ' Svm score for test data:', 0.80736)\n"
     ]
    }
   ],
   "source": [
    "#experimenting on different parameters of svm\n",
    "from sklearn import svm\n",
    "X,Y = train_data,train_labels\n",
    "W = training_data[1:,31]\n",
    "W = W.astype(np.float64)\n",
    "\n",
    "X1 = X[:100000];\n",
    "W1 = W[:100000];\n",
    "Y1 = Y[:100000];\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "print(\"\\nExperimenting for different kernels\")\n",
    "for kernel in kernels:\n",
    "    svc= svm.SVC(kernel=kernel).fit(X1,Y1)\n",
    "#     plotSVC('kernel=' + str(kernel))\n",
    "    svmScore = svc.score(X[100000:200000],Y[100000:200000])\n",
    "    print(\"Kernel \", kernel,\" Svm score for test data:\",svmScore)\n",
    "    \n",
    "print(\"\\nExperimenting for different gammas\")\n",
    "for gamma in gammas:\n",
    "    svc = svm.SVC(kernel='rbf', gamma=gamma).fit(X, Y)\n",
    "    svmScore = svc.score(X[100000:200000],Y[100000:200000])\n",
    "#     plotSVC(‘gamma=’ + str(gamma))\n",
    "    print(\"Gamma:\", gamma,\" Svm score for test data:\",svmScore)\n",
    "    \n",
    "print(\"\\nExperimenting for different Regularization parameters\")\n",
    "for c in Cs:\n",
    "    svc = svm.SVC(kernel='rbf', C=c).fit(X, Y)\n",
    "    svmScore = svc.score(X[100000:200000],Y[100000:200000])\n",
    "#     plotSVC(‘C=’ + str(c))\n",
    "    print(\"C:\", c,\" Svm score for test data:\",svmScore)\n",
    "\n",
    "print(\"\\nExperimenting for different Degrees for polynomial kernel\")\n",
    "degrees = [0, 1, 2, 3, 4]\n",
    "for degree in degrees:\n",
    "    svc = svm.SVC(kernel='poly', degree=degree).fit(X, Y)\n",
    "    svmScore = svc.score(X[100000:200000],Y[100000:200000])\n",
    "    print(\"Degree \", degree,\" Svm score for test data:\",svmScore)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
